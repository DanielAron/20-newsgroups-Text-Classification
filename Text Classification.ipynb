{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# numpy arrays\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# NLP\n",
    "import string\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import re\n",
    "\n",
    "# machine learning\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression     # Logistic Regression\n",
    "from sklearn.naive_bayes import MultinomialNB           # Naive Bayes\n",
    "from sklearn.svm import LinearSVC                       # SVM\n",
    "from sklearn.ensemble import RandomForestClassifier     # Random Forest\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TODO:\n",
    "# install the latest version of `sklearn` to use `plot_confusion_matrix` \n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Model explainability\n",
    "import shap\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# other\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "# load english model\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_n_color_palette(palette_name, n_colors, as_hex=False):\n",
    "    palette = sns.color_palette(palette=palette_name, n_colors=n_colors)\n",
    "    if as_hex:\n",
    "        palette = palette.as_hex()\n",
    "    palette.reverse()\n",
    "    return palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "For faster execution times, select subset of the categories out of the 20 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# subset_categories = ['alt.atheism', 'soc.religion.christian',\n",
    "#                      'comp.graphics', 'sci.med']\n",
    "subset_categories = ['alt.atheism', 'talk.religion.misc', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "newsgroups_data = fetch_20newsgroups(subset='all', categories=subset_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categories = newsgroups_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\n",
    "    'text': newsgroups_data.data,\n",
    "    'category': newsgroups_data.target\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df['category'] = df['category'].apply(lambda x: categories[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# What is this Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. `comp.sys.ibm.pc.hardware` / `comp.sys.mac.hardware`), while others are highly unrelated (e.g `misc.forsale` / `soc.religion.christian`).\n",
    "\n",
    "Here is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<table style='font-family:\"Courier New\", Courier, monospace; font-size:80%'>\n",
    "    <tr>\n",
    "        <td>comp.graphics<br>comp.os.ms-windows.misc<br>comp.sys.ibm.pc.hardware<br>comp.sys.mac.hardware<br>comp.windows.x\n",
    "        </td>\n",
    "        <td>rec.autos<br>rec.motorcycles<br>rec.sport.baseball<br>rec.sport.hockey</td>\n",
    "        <td>sci.crypt<br>sci.electronics<br>sci.med<br>sci.space</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>misc.forsale</td>\n",
    "        <td>talk.politics.misc<br>talk.politics.guns<br>talk.politics.mideast</td>\n",
    "        <td>talk.religion.misc<br>alt.atheism<br>soc.religion.christian</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "One quick *data-cleaning* step is to rename the category column, and use only the last part (`atheism`, `christian`, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# df = df.assign(category=df['category'].apply(lambda x: x.split('.')[-1]))\n",
    "# disable this cell temporairly, and figure out later the best way to name categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Calculate for each category in the dataset the number of articles, the mean article lenght, the max article length, and the min article length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categories_statistics_df = df.groupby(by='category')['text'].agg({\n",
    "                                'count': lambda x: x.size,\n",
    "                                'mean': lambda x: x.str.len().mean(),\n",
    "                                'max': lambda x: x.str.len().max(),\n",
    "                                'min': lambda x: x.str.len().min()\n",
    "                            })\\\n",
    "                            .reset_index()\\\n",
    "                            .sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Categories article count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = px.pie(data_frame=categories_statistics_df, names='category', values='count',\n",
    "            color_discrete_sequence=get_n_color_palette('Blues', 20, True),\n",
    "            title='Categories count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "It's obvious that the dataset is *balanced*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Categories average article length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = px.bar(data_frame=categories_statistics_df.sort_values(by='mean'), x='category', y='mean',\n",
    "            color='mean', title='Average Article Length by Category')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This chart shows how long the *polictics* articles, compared to *computer* articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "en_stop_words = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categories_text_df = df.groupby(by='category')\\\n",
    "                        .agg({\n",
    "                            'text': ' '.join\n",
    "                        })\\\n",
    "                        .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "categories_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_word_cloud(category_name, category_text):\n",
    "    plt.subplots(figsize = (8,8))\n",
    "    wc = WordCloud(background_color=\"white\", stopwords=en_stop_words, width=1000, height=600)\n",
    "    wc.generate(category_text)\n",
    "    plt.title(label=category_name)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for category in df['category'].unique():\n",
    "    plot_word_cloud(category,\n",
    "                    categories_text_df[categories_text_df['category'] == category]['text'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def is_clean_token(token):\n",
    "    return (\n",
    "        not token.is_stop                   # remove stop words\n",
    "        and not token.is_digit              # remove digits\n",
    "        and not token.like_num              # remove numbers\n",
    "        and not token.like_email            # remove emails\n",
    "        and not token.like_url              # remove URLs\n",
    "        and token.is_alpha                  # keep only alphabetic tokens\n",
    "        and token.is_ascii                  # keep only ascii tokens\n",
    "        and len(token.lemma_.lower()) > 2   # keep only token which has length greater than two letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Note**: disabling the *parser* and the *named entity recognizer* components, make the processing of the document much more efficient, and it's advised according to the [Documentation](https://spacy.io/usage/processing-pipelines#disabling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def spacy_analyzer(document):\n",
    "    \n",
    "    # apply the language pipeline on the passed document\n",
    "    # for quicker execution, disable `parser` and `ner` pipeline steps\n",
    "    doc = nlp(document, disable=['parser', 'ner'])\n",
    "    \n",
    "    # clean document\n",
    "    tokens = [token.lemma_.lower() for token in doc if is_clean_token(token)] \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(analyzer=spacy_analyzer, stop_words=en_stop_words,\n",
    "#                              max_df=0.5, min_df=10, max_features=10000)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=en_stop_words,\n",
    "                             max_df=0.5, min_df=10, max_features=10000)\n",
    "\n",
    "# Logistic Regression classifier\n",
    "lr_clf = LogisticRegression(C=1.0, solver='newton-cg', multi_class='multinomial')\n",
    "\n",
    "# Naive Bayes classifier\n",
    "nb_clf = MultinomialNB(alpha=0.01)\n",
    "\n",
    "# SVM classifier\n",
    "svm_clf = LinearSVC(C=1.0)\n",
    "\n",
    "# Random Forest classifier\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100, criterion='gini', \n",
    "                                           max_depth=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', lr_clf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Hyper-parameters tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # vectorizer hyper-parameters\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__max_df': [0.4, 0.5, 0.6],\n",
    "    'vect__min_df': [10, 50, 100],\n",
    "    'vect__max_features': [5000, 10000],\n",
    "    # classifiers\n",
    "    'clf': [lr_clf, nb_clf, svm_clf, random_forest_clf]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, refit=True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "#     for param_name in sorted(parameters.keys()):\n",
    "#         print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## What are the best vectorizer and classifier params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## What is the best estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Here, copy the best parameters of the vectorizer and classifier, to `vect` and `clf` objecs, and then create the pipeline again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Here, fit the pipeline on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Here, use the test data to perform predictions, and measure the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_report = classification_report(y_true=y_test, y_pred=y_pred,\n",
    "                                   target_names=pipeline.named_steps.clf.classes_,\n",
    "                                   output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_report_df = pd.DataFrame(data=clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "clf_report_df.drop(index='support', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data=clf_report_df.T, annot=True, cmap='Blues', fmt='.2f', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true=y_test,\n",
    "                     y_pred=y_pred,\n",
    "                     labels=pipeline.named_steps.clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "conf_matrix_df = pd.DataFrame(data=conf_matrix, columns=pipeline.named_steps.clf.classes_,\n",
    "                                index=pipeline.named_steps.clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data=conf_matrix_df, annot=True, cmap='RdPu', fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Features Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "logistic_regression = pipeline.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "feature_names = pipeline.named_steps['vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_features_importance(clf, feature_names, n_feature=15):\n",
    "    '''\n",
    "    this function takes the classifier object (assuming it has `coef_` attribute)\n",
    "    the list of features, which we can get using the vectorizer,\n",
    "    and the number of features we want to show\n",
    "    it plots for each class label, the most positive and negative features, with their weight\n",
    "    '''\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for i, class_label in enumerate(clf.classes_):\n",
    "        \n",
    "        # get indices of top positive/negative coefficient\n",
    "        negative_coefs_indices = np.argsort(clf.coef_[i])[:n_feature]\n",
    "        positive_coefs_indices = np.argsort(clf.coef_[i])[-n_feature:]\n",
    "        \n",
    "        # get the coefficient values\n",
    "        negative_coefs = [clf.coef_[i][coef_idx] for coef_idx in negative_coefs_indices]\n",
    "        positive_coefs = [clf.coef_[i][coef_idx] for coef_idx in positive_coefs_indices]\n",
    "        \n",
    "        # get the corresponding features names of the top coefficient\n",
    "        negative_features = [feature_names[coef_idx] for coef_idx in negative_coefs_indices]\n",
    "        positive_features = [feature_names[coef_idx] for coef_idx in positive_coefs_indices]\n",
    "        \n",
    "        # stack arrays into one array\n",
    "        coefs = np.hstack([negative_coefs, positive_coefs])\n",
    "        features = np.hstack([negative_features, positive_features])\n",
    "        \n",
    "        res.append([features, coefs, class_label])    \n",
    "        # plot feature names agains their weight, using bar plot\n",
    "#         fig = px.bar(x=features, y=coefs, color=coefs, title=class_label)\n",
    "#         fig.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**TODO**: make the function `plot_features_importance` more general, and move the code of plotting the charts to the function.\n",
    "Hide legend in the plot, and rotate the feature names on the x-axis, so they would be horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "res = plot_features_importance(clf=clf, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bar1, bar2, bar3, bar4 = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles=(bar1[2], bar2[2], bar3[2], bar4[2]))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=bar1[0], y=bar1[1]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=bar2[0], y=bar2[1]),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=bar3[0], y=bar3[1]),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=bar4[0], y=bar4[1]),\n",
    "    row=2, col=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=pipeline.named_steps['clf'].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(f'Document id: {idx}')\n",
    "print(f'Predicted class: {pipeline.predict([X_test.iloc[idx]])[0]}')\n",
    "print(f'True class: {y_test.iloc[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "exp_object = explainer.explain_instance(text_instance=X_test.iloc[idx],\n",
    "                                       classifier_fn=pipeline.predict_proba,\n",
    "                                       top_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "exp_object.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondaec3359f57daf47e5be8d0ffe5590fea3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
